

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Regularization of linear regression model &#8212; Scikit-learn course</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sklearn_mooc.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/sklearn_mooc.js"></script>
    <script src="../_static/matomo.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'python_scripts/linear_models_regularization';</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="üìù Exercise M4.04" href="linear_models_ex_04.html" />
    <link rel="prev" title="üé• Intuitions on regularized linear models" href="../linear_models/regularized_linear_models_slides.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../toc.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/scikit-learn-logo.png" class="logo__image only-light" alt="Scikit-learn course - Home"/>
    <script>document.write(`<img src="../_static/scikit-learn-logo.png" class="logo__image only-dark" alt="Scikit-learn course - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning Concepts</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ml_concepts/slides.html">üé• Introducing machine-learning concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ml_concepts/quiz_intro_01.html">‚úÖ Quiz Intro.01</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">The predictive modeling pipeline</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../predictive_modeling_pipeline/predictive_modeling_module_intro.html">Module overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../predictive_modeling_pipeline/01_tabular_data_exploration_index.html">Tabular data exploration</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="01_tabular_data_exploration.html">First look at our dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="01_tabular_data_exploration_ex_01.html">üìù Exercise M1.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="01_tabular_data_exploration_sol_01.html">üìÉ Solution for Exercise M1.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="../predictive_modeling_pipeline/01_tabular_data_exploration_quiz_m1_01.html">‚úÖ Quiz M1.01</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../predictive_modeling_pipeline/02_numerical_pipeline_index.html">Fitting a scikit-learn model on numerical data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="02_numerical_pipeline_introduction.html">First model with scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_numerical_pipeline_ex_00.html">üìù Exercise M1.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_numerical_pipeline_sol_00.html">üìÉ Solution for Exercise M1.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_numerical_pipeline_hands_on.html">Working with numerical data</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_numerical_pipeline_ex_01.html">üìù Exercise M1.03</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_numerical_pipeline_sol_01.html">üìÉ Solution for Exercise M1.03</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_numerical_pipeline_scaling.html">Preprocessing for numerical features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../predictive_modeling_pipeline/02_numerical_pipeline_video_cross_validation.html">üé• Validation of a model</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_numerical_pipeline_cross_validation.html">Model evaluation using cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../predictive_modeling_pipeline/02_numerical_pipeline_quiz_m1_02.html">‚úÖ Quiz M1.02</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../predictive_modeling_pipeline/03_categorical_pipeline_index.html">Handling categorical data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="03_categorical_pipeline.html">Encoding of categorical variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_categorical_pipeline_ex_01.html">üìù Exercise M1.04</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_categorical_pipeline_sol_01.html">üìÉ Solution for Exercise M1.04</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_categorical_pipeline_column_transformer.html">Using numerical and categorical variables together</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_categorical_pipeline_ex_02.html">üìù Exercise M1.05</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_categorical_pipeline_sol_02.html">üìÉ Solution for Exercise M1.05</a></li>
<li class="toctree-l2"><a class="reference internal" href="../predictive_modeling_pipeline/03_categorical_pipeline_visualization_video.html">üé• Visualizing scikit-learn pipelines in Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_categorical_pipeline_visualization.html">Visualizing scikit-learn pipelines in Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../predictive_modeling_pipeline/03_categorical_pipeline_quiz_m1_03.html">‚úÖ Quiz M1.03</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../predictive_modeling_pipeline/wrap_up_quiz.html">üèÅ Wrap-up quiz 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../predictive_modeling_pipeline/predictive_modeling_module_take_away.html">Main take-away</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Selecting the best model</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../overfit/overfit_module_intro.html">Module overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../overfit/overfit_overfitting_underfitting_index.html">Overfitting and underfitting</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../overfit/overfitting_vs_under_fitting_slides.html">üé• Overfitting and Underfitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_train_test.html">Cross-validation framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overfit/overfitting_vs_under_fitting_quiz_m2_01.html">‚úÖ Quiz M2.01</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../overfit/overfit_validation_learning_curves_index.html">Validation and learning curves</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../overfit/learning_validation_curves_slides.html">üé• Comparing train and test errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_validation_curve.html">Overfit-generalization-underfit</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_learning_curve.html">Effect of the sample size in cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_ex_01.html">üìù Exercise M2.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_sol_01.html">üìÉ Solution for Exercise M2.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overfit/learning_validation_curves_quiz_m2_02.html">‚úÖ Quiz M2.02</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../overfit/overfit_bias_variance_index.html">Bias versus variance trade-off</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../overfit/bias_vs_variance_slides.html">üé• Bias versus Variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overfit/bias_vs_variance_quiz_m2_03.html">‚úÖ Quiz M2.03</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../overfit/overfit_wrap_up_quiz.html">üèÅ Wrap-up quiz 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overfit/overfit_take_away.html">Main take-away</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Hyperparameter tuning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tuning/parameter_tuning_module_intro.html">Module overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tuning/parameter_tuning_manual_index.html">Manual tuning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="parameter_tuning_manual.html">Set and get hyperparameters in scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameter_tuning_ex_02.html">üìù Exercise M3.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameter_tuning_sol_02.html">üìÉ Solution for Exercise M3.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tuning/parameter_tuning_manual_quiz_m3_01.html">‚úÖ Quiz M3.01</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tuning/parameter_tuning_automated_index.html">Automated tuning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="parameter_tuning_grid_search.html">Hyperparameter tuning by grid-search</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameter_tuning_randomized_search.html">Hyperparameter tuning by randomized-search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tuning/parameter_tuning_parallel_plot_video.html">üé• Analysis of hyperparameter search results</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameter_tuning_parallel_plot.html">Analysis of hyperparameter search results</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameter_tuning_nested.html">Evaluation and hyperparameter tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameter_tuning_ex_03.html">üìù Exercise M3.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="parameter_tuning_sol_03.html">üìÉ Solution for Exercise M3.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tuning/parameter_tuning_automated_quiz_m3_02.html">‚úÖ Quiz M3.02</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../tuning/parameter_tuning_wrap_up_quiz.html">üèÅ Wrap-up quiz 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tuning/parameter_tuning_module_take_away.html">Main take-away</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear models</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../linear_models/linear_models_module_intro.html">Module overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linear_models/linear_models_intuitions_index.html">Intuitions on linear models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../linear_models/linear_models_slides.html">üé• Intuitions on linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_regression_without_sklearn.html">Linear regression without scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_models_ex_01.html">üìù Exercise M4.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_models_sol_01.html">üìÉ Solution for Exercise M4.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_regression_in_sklearn.html">Linear regression using scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="logistic_regression.html">Linear models for classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_models/linear_models_quiz_m4_01.html">‚úÖ Quiz M4.01</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linear_models/linear_models_non_linear_index.html">Non-linear feature engineering for linear models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="linear_regression_non_linear_link.html">Non-linear feature engineering for Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_models_ex_02.html">üìù Exercise M4.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_models_sol_02.html">üìÉ Solution for Exercise M4.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_models_feature_engineering_classification.html">Non-linear feature engineering for Logistic Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_models_ex_03.html">üìù Exercise M4.03</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_models_sol_03.html">üìÉ Solution for Exercise M4.03</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_models/linear_models_quiz_m4_02.html">‚úÖ Quiz M4.02</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../linear_models/linear_models_regularization_index.html">Regularization in linear model</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../linear_models/regularized_linear_models_slides.html">üé• Intuitions on regularized linear models</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Regularization of linear regression model</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_models_ex_04.html">üìù Exercise M4.04</a></li>
<li class="toctree-l2"><a class="reference internal" href="linear_models_sol_04.html">üìÉ Solution for Exercise M4.04</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_models/linear_models_quiz_m4_03.html">‚úÖ Quiz M4.03</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_models/linear_models_wrap_up_quiz.html">üèÅ Wrap-up quiz 4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear_models/linear_models_module_take_away.html">Main take-away</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Decision tree models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../trees/trees_module_intro.html">Module overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../trees/trees_intuitions_index.html">Intuitions on tree-based models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../trees/slides.html">üé• Intuitions on tree-based models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../trees/trees_quiz_m5_01.html">‚úÖ Quiz M5.01</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../trees/trees_classification_index.html">Decision tree in classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="trees_classification.html">Build a classification decision tree</a></li>
<li class="toctree-l2"><a class="reference internal" href="trees_ex_01.html">üìù Exercise M5.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="trees_sol_01.html">üìÉ Solution for Exercise M5.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="../trees/trees_quiz_m5_02.html">‚úÖ Quiz M5.02</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../trees/trees_regression_index.html">Decision tree in regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="trees_regression.html">Decision tree for regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="trees_ex_02.html">üìù Exercise M5.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="trees_sol_02.html">üìÉ Solution for Exercise M5.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="../trees/trees_quiz_m5_03.html">‚úÖ Quiz M5.03</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../trees/trees_hyperparameters_index.html">Hyperparameters of decision tree</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="trees_hyperparameters.html">Importance of decision tree hyperparameters on generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../trees/trees_quiz_m5_04.html">‚úÖ Quiz M5.04</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../trees/trees_wrap_up_quiz.html">üèÅ Wrap-up quiz 5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../trees/trees_module_take_away.html">Main take-away</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ensemble of models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ensemble/ensemble_module_intro.html">Module overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ensemble/ensemble_bootstrap_index.html">Ensemble method using bootstrapping</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/bagging_slides.html">üé• Intuitions on ensemble models: bagging</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_introduction.html">Introductory example to ensemble models</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_bagging.html">Bagging</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_ex_01.html">üìù Exercise M6.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_sol_01.html">üìÉ Solution for Exercise M6.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_random_forest.html">Random forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_ex_02.html">üìù Exercise M6.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_sol_02.html">üìÉ Solution for Exercise M6.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/ensemble_quiz_m6_01.html">‚úÖ Quiz M6.01</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ensemble/ensemble_boosting_index.html">Ensemble based on boosting</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/boosting_slides.html">üé• Intuitions on ensemble models: boosting</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_adaboost.html">Adaptive Boosting (AdaBoost)</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_gradient_boosting.html">Gradient-boosting decision tree</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_ex_03.html">üìù Exercise M6.03</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_sol_03.html">üìÉ Solution for Exercise M6.03</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_hist_gradient_boosting.html">Speeding-up gradient-boosting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/ensemble_quiz_m6_02.html">‚úÖ Quiz M6.02</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ensemble/ensemble_hyperparameters_index.html">Hyperparameter tuning with ensemble methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="ensemble_hyperparameters.html">Hyperparameter tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_ex_04.html">üìù Exercise M6.04</a></li>
<li class="toctree-l2"><a class="reference internal" href="ensemble_sol_04.html">üìÉ Solution for Exercise M6.04</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble/ensemble_quiz_m6_03.html">‚úÖ Quiz M6.03</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../ensemble/ensemble_wrap_up_quiz.html">üèÅ Wrap-up quiz 6</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ensemble/ensemble_module_take_away.html">Main take-away</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Evaluating model performance</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../evaluation/evaluation_module_intro.html">Module overview</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../evaluation/cross_validation_baseline_index.html">Comparing a model with simple baselines</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_baseline.html">Comparing model performance with a simple baseline</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_ex_02.html">üìù Exercise M7.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_sol_02.html">üìÉ Solution for Exercise M7.01</a></li>
<li class="toctree-l2"><a class="reference internal" href="../evaluation/evaluation_quiz_m7_01.html">‚úÖ Quiz M7.01</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../evaluation/cross_validation_choices_index.html">Choice of cross-validation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_stratification.html">Stratification</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_grouping.html">Sample grouping</a></li>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_time.html">Non i.i.d. data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../evaluation/evaluation_quiz_m7_02.html">‚úÖ Quiz M7.02</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../evaluation/cross_validation_nested_index.html">Nested cross-validation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cross_validation_nested.html">Nested cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../evaluation/evaluation_quiz_m7_03.html">‚úÖ Quiz M7.03</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../evaluation/metrics_classification_index.html">Classification metrics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="metrics_classification.html">Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics_ex_01.html">üìù Exercise M7.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics_sol_01.html">üìÉ Solution for Exercise M7.02</a></li>
<li class="toctree-l2"><a class="reference internal" href="../evaluation/evaluation_quiz_m7_04.html">‚úÖ Quiz M7.04</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../evaluation/metrics_regression_index.html">Regression metrics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="metrics_regression.html">Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics_ex_02.html">üìù Exercise M7.03</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics_sol_02.html">üìÉ Solution for Exercise M7.03</a></li>
<li class="toctree-l2"><a class="reference internal" href="../evaluation/evaluation_quiz_m7_05.html">‚úÖ Quiz M7.05</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../evaluation/evaluation_wrap_up_quiz.html">üèÅ Wrap-up quiz 7</a></li>
<li class="toctree-l1"><a class="reference internal" href="../evaluation/evaluation_module_take_away.html">Main take-away</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Concluding remarks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../concluding_remarks_video.html">üé• Concluding remarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../concluding_remarks.html">Concluding remarks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../appendix/glossary.html">Glossary</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendix/datasets_intro.html">Datasets description</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="trees_dataset.html">The penguins datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets_adult_census.html">The adult census dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets_california_housing.html">The California housing dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets_ames_housing.html">The Ames housing dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets_blood_transfusion.html">The blood transfusion dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets_bike_rides.html">The bike rides dataset</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/acknowledgement.html">Acknowledgement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/notebook_timings.html">Notebook timings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix/toc_redirect.html">Table of contents</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üöß Feature selection</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../feature_selection/feature_selection_module_intro.html">Module overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_selection_introduction.html">Benefits of using feature selection</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../feature_selection/feature_selection_limitation_index.html">Caveats of feature selection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="feature_selection_ex_01.html">üìù Exercise 01</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection_sol_01.html">üìÉ Solution for Exercise 01</a></li>
<li class="toctree-l2"><a class="reference internal" href="feature_selection_limitation_model.html">Limitation of selecting feature using a model</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../feature_selection/feature_selection_module_take_away.html">Main take-away</a></li>
<li class="toctree-l1"><a class="reference internal" href="../feature_selection/feature_selection_quiz.html">‚úÖ Quiz</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">üöß Interpretation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dev_features_importance.html">Feature importance</a></li>

<li class="toctree-l1"><a class="reference internal" href="../interpretation/interpretation_quiz.html">‚úÖ Quiz</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/INRIA/scikit-learn-mooc/main?urlpath=tree/python_scripts/linear_models_regularization.py" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/INRIA/scikit-learn-mooc" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/INRIA/scikit-learn-mooc/edit/main/python_scripts/linear_models_regularization.py" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/INRIA/scikit-learn-mooc/issues/new?title=Issue%20on%20page%20%2Fpython_scripts/linear_models_regularization.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/python_scripts/linear_models_regularization.py" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.py</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Regularization of linear regression model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-of-regularization">Effect of regularization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-scaling-and-regularization">Feature scaling and regularization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tuning-the-regularization-parameter">Tuning the regularization parameter</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="regularization-of-linear-regression-model">
<h1>Regularization of linear regression model<a class="headerlink" href="#regularization-of-linear-regression-model" title="Permalink to this heading">#</a></h1>
<p>In this notebook, we explore some limitations of linear regression models and
demonstrate the benefits of using regularized models instead. Additionally, we
discuss the importance of scaling the data when working with regularized
models, especially when tuning the regularization parameter.</p>
<p>We start by highlighting the problem of overfitting that can occur with a
simple linear regression model.</p>
<section id="effect-of-regularization">
<h2>Effect of regularization<a class="headerlink" href="#effect-of-regularization" title="Permalink to this heading">#</a></h2>
<p>We load the Ames housing dataset. We retain some specific
<code class="docutils literal notranslate"><span class="pre">features_of_interest</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you want a deeper overview regarding this dataset, you can refer to the
Appendix - Datasets description section at the end of this MOOC.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">ames_housing</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../datasets/ames_housing_no_missing.csv&quot;</span><span class="p">)</span>
<span class="n">features_of_interest</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;LotFrontage&quot;</span><span class="p">,</span>
    <span class="s2">&quot;LotArea&quot;</span><span class="p">,</span>
    <span class="s2">&quot;PoolArea&quot;</span><span class="p">,</span>
    <span class="s2">&quot;YearBuilt&quot;</span><span class="p">,</span>
    <span class="s2">&quot;YrSold&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">target_name</span> <span class="o">=</span> <span class="s2">&quot;SalePrice&quot;</span>
<span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ames_housing</span><span class="p">[</span><span class="n">features_of_interest</span><span class="p">],</span>
    <span class="n">ames_housing</span><span class="p">[</span><span class="n">target_name</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In one of the previous notebooks, we showed that linear models could be used
even when there is no linear relationship between the <code class="docutils literal notranslate"><span class="pre">data</span></code> and <code class="docutils literal notranslate"><span class="pre">target</span></code>.
For instance, one can use the <code class="docutils literal notranslate"><span class="pre">PolynomialFeatures</span></code> transformer to create
additional features that capture some non-linear interactions between them.</p>
<p>Here, we use this transformer to augment the feature space. Subsequently, we
train a linear regression model. We use cross-validation with
<code class="docutils literal notranslate"><span class="pre">return_train_score=True</span></code> to evaluate both the train scores and the
generalization capabilities of our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">linear_regression</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="p">)</span><span class="o">.</span><span class="n">set_output</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">)</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
    <span class="n">linear_regression</span><span class="p">,</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">target</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can compare the mean squared error on the training and testing set to
assess the generalization performance of our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_error</span> <span class="o">=</span> <span class="o">-</span><span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;train_score&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Mean squared error of linear regression model on the train set:</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">train_error</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2"> ¬± </span><span class="si">{</span><span class="n">train_error</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean squared error of linear regression model on the train set:
2.85e+09 ¬± 8.63e+07
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_error</span> <span class="o">=</span> <span class="o">-</span><span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Mean squared error of linear regression model on the test set:</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">test_error</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2"> ¬± </span><span class="si">{</span><span class="n">test_error</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean squared error of linear regression model on the test set:
8.69e+10 ¬± 2.47e+11
</pre></div>
</div>
</div>
</div>
<p>The training error is in average one order of magnitude lower than the testing
error (lower error is better). Such a gap between the training and testing
scores is an indication that our model overfitted the training set. Indeed,
this is one of the dangers when augmenting the number of features with a
<code class="docutils literal notranslate"><span class="pre">PolynomialFeatures</span></code> transformer. For instance, one does not expect features
such as <code class="docutils literal notranslate"><span class="pre">PoolArea</span> <span class="pre">*</span> <span class="pre">YrSold</span></code> to be very predictive.</p>
<p>To analyze the weights of the model, we can create a dataframe. The columns of
the dataframe contain the feature names, while the rows store the coefficients
of each model of a given cross-validation fold.</p>
<p>In order to obtain the feature names associated with each feature combination,
we need to extract them from the augmented data created by
<code class="docutils literal notranslate"><span class="pre">PolynomialFeatures</span></code>. Fortunately, scikit-learn provides a convenient method
called <code class="docutils literal notranslate"><span class="pre">feature_names_in_</span></code> for this purpose. Let‚Äôs begin by retrieving the
coefficients from the model fitted in the first cross-validation fold.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_first_fold</span> <span class="o">=</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">model_first_fold</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "‚ñ∏";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "‚ñæ";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;polynomialfeatures&#x27;, PolynomialFeatures(include_bias=False)),
                (&#x27;linearregression&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;polynomialfeatures&#x27;, PolynomialFeatures(include_bias=False)),
                (&#x27;linearregression&#x27;, LinearRegression())])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;PolynomialFeatures<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.PolynomialFeatures.html">?<span>Documentation for PolynomialFeatures</span></a></label><div class="sk-toggleable__content fitted"><pre>PolynomialFeatures(include_bias=False)</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;LinearRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html">?<span>Documentation for LinearRegression</span></a></label><div class="sk-toggleable__content fitted"><pre>LinearRegression()</pre></div> </div></div></div></div></div></div></div></div>
</div>
<p>Now, we can access the fitted <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> (step <code class="docutils literal notranslate"><span class="pre">-1</span></code> i.e. the last step
of the <code class="docutils literal notranslate"><span class="pre">linear_regression</span></code> pipeline) to recover the feature names.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_names</span> <span class="o">=</span> <span class="n">model_first_fold</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">feature_names_in_</span>
<span class="n">feature_names</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;PoolArea&#39;, &#39;YearBuilt&#39;, &#39;YrSold&#39;,
       &#39;LotFrontage^2&#39;, &#39;LotFrontage LotArea&#39;, &#39;LotFrontage PoolArea&#39;,
       &#39;LotFrontage YearBuilt&#39;, &#39;LotFrontage YrSold&#39;, &#39;LotArea^2&#39;,
       &#39;LotArea PoolArea&#39;, &#39;LotArea YearBuilt&#39;, &#39;LotArea YrSold&#39;,
       &#39;PoolArea^2&#39;, &#39;PoolArea YearBuilt&#39;, &#39;PoolArea YrSold&#39;,
       &#39;YearBuilt^2&#39;, &#39;YearBuilt YrSold&#39;, &#39;YrSold^2&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<p>The following code creates a list by iterating through the estimators and
querying their last step for the learned <code class="docutils literal notranslate"><span class="pre">coef_</span></code>. We can then create the
dataframe containing all the information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">coefs</span> <span class="o">=</span> <span class="p">[</span><span class="n">est</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span> <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]]</span>
<span class="n">weights_linear_regression</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let‚Äôs use a box plot to see the coefficients variations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">color</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;whiskers&quot;</span><span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="s2">&quot;medians&quot;</span><span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="s2">&quot;caps&quot;</span><span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">}</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">weights_linear_regression</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Linear regression weights (linear scale)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/89647f0964b04b0d13e453d49af869221a06950d8d5b9d06e80bc0104966e0a2.png" src="../_images/89647f0964b04b0d13e453d49af869221a06950d8d5b9d06e80bc0104966e0a2.png" />
</div>
</div>
<p>By looking at the bar plot above it would seem that most of the features are
very close to zero, but this is just an effect of visualizing them on the same
scale as the extremely large span of <code class="docutils literal notranslate"><span class="pre">&quot;YrSold&quot;</span></code>. Instead we can use a
symmetric log scale for the plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">color</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;whiskers&quot;</span><span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="s2">&quot;medians&quot;</span><span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="s2">&quot;caps&quot;</span><span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">}</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">weights_linear_regression</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Linear regression weights (symmetric log scale)&quot;</span><span class="p">,</span>
    <span class="n">xscale</span><span class="o">=</span><span class="s2">&quot;symlog&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f385414ee31f4414f4e899be44f599173bb62f2e37b0c27f591c68c4c0e5e3a7.png" src="../_images/f385414ee31f4414f4e899be44f599173bb62f2e37b0c27f591c68c4c0e5e3a7.png" />
</div>
</div>
<p>Observe that some coefficients are extremely large while others are extremely
small, yet non-zero. Furthermore, the coefficient values can be very unstable
across cross-validation folds.</p>
<p>We can force the linear regression model to consider all features in a more
homogeneous manner. In fact, we could force large positive or negative
weights to shrink toward zero. This is known as regularization. We use a
ridge model which enforces such behavior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>

<span class="n">ridge</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;cholesky&quot;</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
    <span class="n">ridge</span><span class="p">,</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">target</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59923e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59556e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59609e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.11828e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.06109e-19): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.60121e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.61694e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59735e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59566e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.72304e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.60047e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59824e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59593e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59564e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.5959e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59553e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.59686e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.60737e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.5957e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.60243e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a=&quot;pos&quot;, overwrite_a=True).T
</pre></div>
</div>
</div>
</div>
<p>The code cell above can generate a couple of warnings (depending on the
choice of solver) because the features included both extremely large and
extremely small values, which are causing numerical problems when training
the predictive model. We will get to that in a bit.</p>
<p>Let us evaluate the train and test scores of this model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_error</span> <span class="o">=</span> <span class="o">-</span><span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;train_score&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Mean squared error of ridge model on the train set:</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">train_error</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2"> ¬± </span><span class="si">{</span><span class="n">train_error</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean squared error of ridge model on the train set:
2.90e+09 ¬± 6.56e+07
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_error</span> <span class="o">=</span> <span class="o">-</span><span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Mean squared error of ridge model on the test set:</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">test_error</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2"> ¬± </span><span class="si">{</span><span class="n">test_error</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean squared error of ridge model on the test set:
4.55e+10 ¬± 1.68e+11
</pre></div>
</div>
</div>
</div>
<p>We see that the training and testing scores get closer, indicating that our
model is less overfitting (yet still overfitting!). We can compare the values
of the weights of ridge with the un-regularized linear regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coefs</span> <span class="o">=</span> <span class="p">[</span><span class="n">est</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span> <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]]</span>
<span class="n">weights_ridge</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">weights_ridge</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Ridge regression weights&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0dfd1a0f512750dbc9cd84a006605bbd2770bf185e2778e26d88f0ab5bf9fda2.png" src="../_images/0dfd1a0f512750dbc9cd84a006605bbd2770bf185e2778e26d88f0ab5bf9fda2.png" />
</div>
</div>
<p>Notice that the overall magnitudes of the weights are shrunk
(yet non-zero!) with respect to the linear regression model. If you want to,
feel free to use a symmetric log scale in the previous plot.</p>
<p>You can also observe that even if the weights‚Äô values are less extreme, they
are still unstable from one fold to another. Even worst, the results can vary
a lot depending on the choice of the solver (for instance try to set
<code class="docutils literal notranslate"><span class="pre">solver=&quot;saga&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">solver=&quot;lsqr&quot;</span></code> instead of <code class="docutils literal notranslate"><span class="pre">solver=&quot;cholesky&quot;</span></code> and re-run
the above cells).</p>
<p>In the following we attempt to resolve those remaining problems, by
focusing on two important aspects we omitted so far:</p>
<ul class="simple">
<li><p>the need to <strong>scale the data</strong>, and</p></li>
<li><p>the need to <strong>search for the best regularization parameter</strong>.</p></li>
</ul>
</section>
<section id="feature-scaling-and-regularization">
<h2>Feature scaling and regularization<a class="headerlink" href="#feature-scaling-and-regularization" title="Permalink to this heading">#</a></h2>
<p>On the one hand, weights define the association between feature values and the
predicted target, which depends on the scales of both the feature values and
the target. On the other hand, regularization adds constraints on the weights
of the model through the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> parameter. Therefore, the effect that feature
rescaling has on the final weights also interacts with the use of
regularization.</p>
<p>Let‚Äôs consider the case where features live on the same scale/units: if two
features are found to be equally important by the model, they are affected
similarly by the regularization strength.</p>
<p>Now, let‚Äôs consider the scenario where two features have completely different
data scales (for instance age in years and annual revenue in dollars). Let‚Äôs
also assume that both features are approximately equally predictive and are
not too correlated. Fitting a linear regression without scaling and without
regularization would give a higher weight to the feature with the smallest
natural scale. If we add regularization, the feature with the smallest natural
scale would be penalized more than the other feature. This is not desirable
given the hypothesis that both features are equally important. In such case we
require the regularization to stay neutral.</p>
<p>In practice, we don‚Äôt know ahead of time which features are predictive, and
therefore we want regularization to treat all features approximately equally
by default. This can be achieved by rescaling the features.</p>
<p>Furthermore, many numerical solvers used internally in scikit-learn behave
better when features are approximately on the same scale. Heterogeneously
scaled data can be detrimental when solving for the optimal weights (hence the
warnings we tend to get when fitting linear models on raw data). Therefore,
when working with a linear model and numerical data, it is generally a good
practice to scale the data.</p>
<p>Thus, we add a <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> in the machine learning pipeline, which scales
each feature individually such that its range maps into the range between zero
and one. We place it just before the <code class="docutils literal notranslate"><span class="pre">PolynomialFeatures</span></code> transformer as
powers of features in the range between zero and one remain in the same range.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="n">scaled_ridge</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">MinMaxScaler</span><span class="p">(),</span>
    <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;cholesky&quot;</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
    <span class="n">scaled_ridge</span><span class="p">,</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">target</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_error</span> <span class="o">=</span> <span class="o">-</span><span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;train_score&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Mean squared error of scaled ridge model on the train set:</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">train_error</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2"> ¬± </span><span class="si">{</span><span class="n">train_error</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean squared error of scaled ridge model on the train set:
3.78e+09 ¬± 1.21e+08
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_error</span> <span class="o">=</span> <span class="o">-</span><span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Mean squared error of scaled ridge model on the test set:</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">test_error</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2"> ¬± </span><span class="si">{</span><span class="n">test_error</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean squared error of scaled ridge model on the test set:
3.83e+09 ¬± 1.17e+09
</pre></div>
</div>
</div>
</div>
<p>We observe that scaling data has a positive impact on the test error: it is
now both lower and closer to the train error. It means that our model is less
overfitted and that we are getting closer to the best generalization sweet
spot.</p>
<p>If you want to try different solvers, you can notice that fitting this
pipeline no longer generates any warning regardless of such choice.
Additionally, changing the solver should no longer result in significant
changes in the weights.</p>
<p>Let‚Äôs have an additional look to the different weights.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coefs</span> <span class="o">=</span> <span class="p">[</span><span class="n">est</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span> <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]]</span>
<span class="n">weights_ridge_scaled_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">weights_ridge_scaled_data</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Ridge regression weights with data scaling&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/584f1efa7d73eba570783c86ff92296dc3ee9d18d67dc9398fa69428b73907d2.png" src="../_images/584f1efa7d73eba570783c86ff92296dc3ee9d18d67dc9398fa69428b73907d2.png" />
</div>
</div>
<p>Compared to the previous plots, we see that now most weight magnitudes have a
similar order of magnitude, i.e. they are more equally contributing. The
number of unstable weights also decreased.</p>
<p>In the previous model, we set <code class="docutils literal notranslate"><span class="pre">alpha=10</span></code>. We can now check the impact of
<code class="docutils literal notranslate"><span class="pre">alpha</span></code> by increasing it to a very large value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ridge_large_alpha</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">MinMaxScaler</span><span class="p">(),</span>
    <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1_000_000</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lsqr&quot;</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
    <span class="n">ridge_large_alpha</span><span class="p">,</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">target</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coefs</span> <span class="o">=</span> <span class="p">[</span><span class="n">est</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span> <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]]</span>
<span class="n">weights_ridge_scaled_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">weights_ridge_scaled_data</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Ridge regression weights with data scaling and large alpha&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ff584b4f613ab5b5735be9a156eb9da12a152113fce3fd10ac178d36a268aa26.png" src="../_images/ff584b4f613ab5b5735be9a156eb9da12a152113fce3fd10ac178d36a268aa26.png" />
</div>
</div>
<p>When examining the weight values, we notice that as the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> value
increases, the weights decrease. A negative value of <code class="docutils literal notranslate"><span class="pre">alpha</span></code> can lead to
unpredictable and unstable behavior in the model.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Here, we only focus on numerical features. For categorical features, it is
generally common to omit scaling when features are encoded with a
<code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code> since the feature values are already on a similar scale.</p>
<p>However, this choice may depend on the scaling method and the user case. For
instance, standard scaling categorical features that are imbalanced (e.g. more
occurrences of a specific category) would even out the impact of
regularization to each category. However, scaling such features in the
presence of rare categories could be problematic (i.e. division by a very
small standard deviation) and it can therefore introduce numerical issues.</p>
</div>
<p>In the previous analysis, we chose the parameter beforehand and fixed it for
the analysis. In the next section, we check how the regularization parameter
<code class="docutils literal notranslate"><span class="pre">alpha</span></code> should be tuned.</p>
</section>
<section id="tuning-the-regularization-parameter">
<h2>Tuning the regularization parameter<a class="headerlink" href="#tuning-the-regularization-parameter" title="Permalink to this heading">#</a></h2>
<p>As mentioned, the regularization parameter needs to be tuned on each dataset.
The default parameter does not lead to the optimal model. Therefore, we need
to tune the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> parameter.</p>
<p>Model hyperparameter tuning should be done with care. Indeed, we want to find
an optimal parameter that maximizes some metrics. Thus, it requires both a
training set and testing set.</p>
<p>However, this testing set should be different from the out-of-sample testing
set that we used to evaluate our model: if we use the same one, we are using
an <code class="docutils literal notranslate"><span class="pre">alpha</span></code> which was optimized for this testing set and it breaks the
out-of-sample rule.</p>
<p>Therefore, we should include search of the hyperparameter <code class="docutils literal notranslate"><span class="pre">alpha</span></code> within the
cross-validation. As we saw in previous notebooks, we could use a grid-search.
However, some predictor in scikit-learn are available with an integrated
hyperparameter search, more efficient than using a grid-search. The name of
these predictors finishes by <code class="docutils literal notranslate"><span class="pre">CV</span></code>. In the case of <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, scikit-learn
provides a <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code> regressor.</p>
<p>Cross-validating a pipeline that contains such predictors allows to make a
nested cross-validation: the inner cross-validation searches for the best
alpha, while the outer cross-validation gives an estimate of the testing
score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">MinMaxScaler</span><span class="p">(),</span>
    <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">store_cv_values</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
    <span class="n">ridge</span><span class="p">,</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">target</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:2341: FutureWarning: &#39;store_cv_values&#39; is deprecated in version 1.5 and will be removed in 1.7. Use &#39;store_cv_results&#39; instead.
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_error</span> <span class="o">=</span> <span class="o">-</span><span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;train_score&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Mean squared error of tuned ridge model on the train set:</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">train_error</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2"> ¬± </span><span class="si">{</span><span class="n">train_error</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean squared error of tuned ridge model on the train set:
3.12e+09 ¬± 1.25e+08
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_error</span> <span class="o">=</span> <span class="o">-</span><span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Mean squared error of tuned ridge model on the test set:</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">test_error</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2"> ¬± </span><span class="si">{</span><span class="n">test_error</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean squared error of tuned ridge model on the test set:
3.50e+09 ¬± 1.40e+09
</pre></div>
</div>
</div>
</div>
<p>By optimizing <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, we see that the training and testing scores are close.
It indicates that our model is not overfitting.</p>
<p>When fitting the ridge regressor, we also requested to store the error found
during cross-validation (by setting the parameter <code class="docutils literal notranslate"><span class="pre">store_cv_values=True</span></code>). We
can plot the mean squared error for the different <code class="docutils literal notranslate"><span class="pre">alphas</span></code> regularization
strengths that we tried. The error bars represent one standard deviation of the
average mean square error across folds for a given value of <code class="docutils literal notranslate"><span class="pre">alpha</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mse_alphas</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">est</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cv_values_</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]</span>
<span class="p">]</span>
<span class="n">cv_alphas</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">mse_alphas</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">alphas</span><span class="p">)</span>
<span class="n">cv_alphas</span> <span class="o">=</span> <span class="n">cv_alphas</span><span class="o">.</span><span class="n">aggregate</span><span class="p">([</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
<span class="n">cv_alphas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/sklearn/utils/deprecation.py:102: FutureWarning: Attribute `cv_values_` is deprecated in version 1.5 and will be removed in 1.7. Use `cv_results_` instead.
  warnings.warn(msg, category=FutureWarning)
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>std</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1.000000e-07</th>
      <td>5.841881e+10</td>
      <td>5.347783e+10</td>
    </tr>
    <tr>
      <th>1.321941e-07</th>
      <td>5.837563e+10</td>
      <td>5.343115e+10</td>
    </tr>
    <tr>
      <th>1.747528e-07</th>
      <td>5.831866e+10</td>
      <td>5.336956e+10</td>
    </tr>
    <tr>
      <th>2.310130e-07</th>
      <td>5.824352e+10</td>
      <td>5.328835e+10</td>
    </tr>
    <tr>
      <th>3.053856e-07</th>
      <td>5.814452e+10</td>
      <td>5.318133e+10</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3.274549e+04</th>
      <td>6.319038e+09</td>
      <td>1.337394e+08</td>
    </tr>
    <tr>
      <th>4.328761e+04</th>
      <td>6.324503e+09</td>
      <td>1.338181e+08</td>
    </tr>
    <tr>
      <th>5.722368e+04</th>
      <td>6.328652e+09</td>
      <td>1.338778e+08</td>
    </tr>
    <tr>
      <th>7.564633e+04</th>
      <td>6.331799e+09</td>
      <td>1.339232e+08</td>
    </tr>
    <tr>
      <th>1.000000e+05</th>
      <td>6.334185e+09</td>
      <td>1.339576e+08</td>
    </tr>
  </tbody>
</table>
<p>100 rows √ó 2 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">cv_alphas</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">cv_alphas</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span> <span class="n">yerr</span><span class="o">=</span><span class="n">cv_alphas</span><span class="p">[</span><span class="s2">&quot;std&quot;</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xscale</span><span class="o">=</span><span class="s2">&quot;log&quot;</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span>
    <span class="n">yscale</span><span class="o">=</span><span class="s2">&quot;log&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Mean squared error</span><span class="se">\n</span><span class="s2"> (lower is better)&quot;</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Testing error in RidgeCV&#39;s inner cross-validation&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/711c276b4ae44a9a92504f2103556f252680e51eacd09f11dd75d2700540315f.png" src="../_images/711c276b4ae44a9a92504f2103556f252680e51eacd09f11dd75d2700540315f.png" />
</div>
</div>
<p>As we can see, regularization is just like salt in cooking: one must balance
its amount to get the best generalization performance. We can check if the
best <code class="docutils literal notranslate"><span class="pre">alpha</span></code> found is stable across the cross-validation fold.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_alphas</span> <span class="o">=</span> <span class="p">[</span><span class="n">est</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">alpha_</span> <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="n">cv_results</span><span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]]</span>
<span class="n">best_alphas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[np.float64(0.11497569953977356),
 np.float64(0.35111917342151344),
 np.float64(0.1519911082952933),
 np.float64(0.35111917342151344),
 np.float64(0.11497569953977356),
 np.float64(0.4641588833612782),
 np.float64(0.4641588833612782),
 np.float64(0.4641588833612782),
 np.float64(0.4641588833612782),
 np.float64(0.35111917342151344),
 np.float64(0.35111917342151344),
 np.float64(0.4641588833612782),
 np.float64(0.11497569953977356),
 np.float64(0.11497569953977356),
 np.float64(0.35111917342151344),
 np.float64(0.4641588833612782),
 np.float64(0.11497569953977356),
 np.float64(0.35111917342151344),
 np.float64(0.35111917342151344),
 np.float64(0.35111917342151344),
 np.float64(0.35111917342151344),
 np.float64(0.4641588833612782),
 np.float64(0.35111917342151344),
 np.float64(0.4641588833612782),
 np.float64(0.35111917342151344),
 np.float64(0.35111917342151344),
 np.float64(0.35111917342151344),
 np.float64(0.08697490026177834),
 np.float64(0.6135907273413176),
 np.float64(0.4641588833612782),
 np.float64(0.35111917342151344),
 np.float64(0.4641588833612782),
 np.float64(0.4641588833612782),
 np.float64(0.11497569953977356),
 np.float64(0.35111917342151344),
 np.float64(0.35111917342151344),
 np.float64(0.4641588833612782),
 np.float64(0.35111917342151344),
 np.float64(0.11497569953977356),
 np.float64(0.08697490026177834),
 np.float64(0.4641588833612782),
 np.float64(0.4641588833612782),
 np.float64(0.35111917342151344),
 np.float64(0.35111917342151344),
 np.float64(0.4641588833612782),
 np.float64(0.35111917342151344),
 np.float64(0.35111917342151344),
 np.float64(0.35111917342151344),
 np.float64(0.4641588833612782),
 np.float64(0.35111917342151344)]
</pre></div>
</div>
</div>
</div>
<p>The optimal regularization strength is not necessarily the same on all
cross-validation iterations. But since we expect each cross-validation
resampling to stem from the same data distribution, it is common practice to
choose the best <code class="docutils literal notranslate"><span class="pre">alpha</span></code> to put into production as lying in the range defined
by:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Min optimal alpha: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">best_alphas</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> and &quot;</span>
    <span class="sa">f</span><span class="s2">&quot;Max optimal alpha: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">best_alphas</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Min optimal alpha: 0.09 and Max optimal alpha: 0.61
</pre></div>
</div>
</div>
</div>
<p>This range can be reduced depending on the feature engineering and
preprocessing.</p>
<p>Here is a summary of important points highlighted in this notebook:</p>
<ul class="simple">
<li><p>scaling features makes the effect of regularization more even: all variables
are regularized by comparable magnitude, which would not necessarily be the
case with the natural feature scales;</p></li>
<li><p>scaling features makes the numerical solvers more stable which is also
helpful to tune the regularization parameter more independently of the
choice of the solver used to fit the linear model;</p></li>
<li><p>tuning the regularization parameter of the <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> estimator can be done
very efficiently by using the <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code> class. Wrapping it into a
<code class="docutils literal notranslate"><span class="pre">cross_validate</span></code> call makes it possible to assess the true generalization
power of the whole pipeline by including the tuning of the regularization
parameter as part of the learning process: this is an example of ‚Äúnested
cross-validation‚Äù;</p></li>
<li><p>doing so makes it possible to check that the optimal value of the
regularization strength <code class="docutils literal notranslate"><span class="pre">alpha</span></code> is robust to a resampling of the dataset. If
it wasn‚Äôt the case it would hint at a problem with the dataset (e.g.
presence of outliers in the features or the target that influence the
learning process disproportionately) or a bad choice of other elements of
the feature engineering pipeline.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./python_scripts"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../linear_models/regularized_linear_models_slides.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">üé• Intuitions on regularized linear models</p>
      </div>
    </a>
    <a class="right-next"
       href="linear_models_ex_04.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">üìù Exercise M4.04</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-of-regularization">Effect of regularization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-scaling-and-regularization">Feature scaling and regularization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tuning-the-regularization-parameter">Tuning the regularization parameter</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By scikit-learn developers
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2022-2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div>
  <div class="mooc_add">
   <a href="https://www.fun-mooc.fr/en/courses/machine-learning-python-scikit-learn">Join the full MOOC for better learning!</a>
  </div>
  Brought to you under a <a href="https://github.com/INRIA/scikit-learn-mooc/blob/main/LICENSE">CC-BY License</a> by
  <a href="https://learninglab.inria.fr">Inria Learning Lab</a>,
  <a href="https://scikit-learn.fondation-inria.fr">scikit-learn @ La Fondation Inria</a>,
  <a href="https://www.inria-academy.fr/formation/scikit-learn-la-boite-a-outils-de-lapprentissage-automatique/">Inria Academy</a>,
  with many thanks to the <a href="https://scikit-learn.org">scikit-learn</a> community as a whole!
</div>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>